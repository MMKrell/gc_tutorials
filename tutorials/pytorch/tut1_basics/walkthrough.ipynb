{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "554c531b",
   "metadata": {},
   "source": [
    "Copyright (c) 2020 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d718dc",
   "metadata": {},
   "source": [
    "# Introduction to PopTorch - running a simple model\n",
    "\n",
    "This tutorial covers the basics of model making in PyTorch, using\n",
    "`torch.nn.Module`, and the specific methods to convert a PyTorch model to\n",
    "a PopTorch model so that it can be run on a Graphcore IPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52224b05",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "- A Poplar SDK environment enabled\n",
    "   (see the [Getting Started](https://docs.graphcore.ai/en/latest/getting-started.html) guide for your IPU system)\n",
    "- Python packages installed with `python -m pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe70d5e",
   "metadata": {
    "tags": [
     "sst_ignore_md",
     "sst_ignore_code_only"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59362c8",
   "metadata": {},
   "source": [
    "To run the Jupyter notebook version of this tutorial:\n",
    "1. Enable a Poplar SDK environment and install required packages with `python -m pip install -r requirements.txt`\n",
    "2. In the same environment, install the Jupyter notebook server: `python -m pip install notebook`\n",
    "3. Launch a Jupyter Server on a specific port: `jupyter-notebook --no-browser --port <port number>`\n",
    "4. Connect via SSH to your remote machine, forwarding your chosen port:\n",
    "`ssh -NL <port number>:localhost:<port number> <your username>@<remote machine>`\n",
    "\n",
    "For more details about this process, or if you need troubleshooting, see our [guide on using IPUs from Jupyter notebooks](../../standard_tools/using_jupyter/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a086a14",
   "metadata": {},
   "source": [
    "## What is PopTorch?\n",
    "PopTorch is a set of extensions for PyTorch to enable PyTorch models to run\n",
    "on Graphcore's IPU hardware.\n",
    "\n",
    "PopTorch supports both inference and training. To run a model on the IPU you\n",
    "wrap your existing PyTorch model in either a PopTorch inference wrapper or\n",
    "a PopTorch training wrapper. You can provide further annotations to partition\n",
    "the model across multiple IPUs.\n",
    "\n",
    "You can wrap individual layers in an IPU helper to designate which IPU they\n",
    "should go on. Using your annotations, PopTorch will use [PopART](https://docs.graphcore.ai/projects/popart-user-guide)\n",
    "to parallelise the model over the given number of IPUs. Additional parallelism\n",
    "can be expressed via a replication factor which enables you to\n",
    "data-parallelise the model over more IPUs.\n",
    "\n",
    "Under the hood PopTorch uses [TorchScript](https://pytorch.org/docs/stable/jit.html),\n",
    "an intermediate representation (IR) of a PyTorch model, using the\n",
    "`torch.jit.trace` API. That means it inherits the constraints of that API.\n",
    "These include:\n",
    "- Inputs must be Torch tensors or tuples/lists containing Torch tensors\n",
    "- None can be used as a default value for a parameter but cannot be\n",
    "explicitly passed as an input value\n",
    "- Hooks and `.grad` cannot be used to inspect weights and gradients\n",
    "- `torch.jit.trace` cannot handle control flow or shape variations within\n",
    "the model. That is, the inputs passed at run-time cannot vary the control\n",
    "flow of the model or the shapes/sizes of results.\n",
    "\n",
    "To learn more about TorchScript and JIT, you can go through the [Introduction to TorchScript tutorial](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html).\n",
    "\n",
    "PopTorch has been designed to require few manual alterations to your models\n",
    "in order to run them on IPU. However, it does have some differences from\n",
    "native PyTorch execution. Also, not all PyTorch operations have been\n",
    "implemented by the backend yet. You can find the list of supported operations [here](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/supported_ops.html).\n",
    "\n",
    "![Software stack](static/stack.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43fea54",
   "metadata": {},
   "source": [
    "# Getting started: training a model on the IPU\n",
    "We will do the following steps in order:\n",
    "1. Load the Fashion-MNIST dataset using `torchvision.datasets` and\n",
    "`poptorch.DataLoader`.\n",
    "2. Define a deep CNN  and a loss function using the `torch` API.\n",
    "3. Train the model on an IPU using `poptorch.trainingModel`.\n",
    "4. Evaluate the model on the IPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed12944",
   "metadata": {},
   "source": [
    "### Import the packages\n",
    "PopTorch is a separate package from PyTorch, and available\n",
    "in Graphcore's Poplar SDK. Both must thus be imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793cc530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import poptorch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84704abf",
   "metadata": {},
   "source": [
    "Under the hood, PopTorch uses Graphcore's high-performance\n",
    "machine learning framework PopART. It is therefore necessary\n",
    "to enable PopART and Poplar in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac41305f",
   "metadata": {},
   "source": [
    ">**NOTE**:\n",
    ">If you forget to enable PopART, you will encounter the error when importing `poptorch`:\n",
    ">`ImportError: libpopart.so: cannot open shared object file: No such file or directory`\n",
    ">If the error message says something like:\n",
    ">`libpopart_compiler.so: undefined symbol: _ZN6popart7Session3runERNS_7IStepIOE`,\n",
    ">it most likely means the versions of PopART and PopTorch do not match,\n",
    ">for example by enabling PopART with a previous SDK release's `enable.sh`\n",
    ">script. Make sure to not mix SDK artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4410eb08",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "We will use the Fashion-MNIST dataset made available by the package\n",
    "`torchvision`. This dataset, from [Zalando](https://github.com/zalandoresearch/fashion-mnist),\n",
    "can be used as a more challenging replacement to the well-known MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3746e14",
   "metadata": {},
   "source": [
    "The dataset consists of 28x28 grayscale images and labels of range `[0, 9]`\n",
    "from 10 classes: T-shirt, trouser, pullover, dress, coat, sandal, shirt,\n",
    "sneaker, bag and ankle boot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99150eb",
   "metadata": {},
   "source": [
    "In order for the images to be usable by PyTorch, we have to convert them to\n",
    "`torch.Tensor` objects. Also, data normalisation improves overall\n",
    "performance. We will apply both operations, conversion and normalisation, to\n",
    "the datasets using `torchvision.transforms` and feed these ops to\n",
    "`torchvision.datasets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc8c054",
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    \"~/.torch/datasets\", transform=transform, download=True, train=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    \"~/.torch/datasets\", transform=transform, download=True, train=False)\n",
    "\n",
    "classes = (\"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\",\n",
    "           \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77812a7",
   "metadata": {},
   "source": [
    "With the following method, we can visualise and save a sample of these images and their\n",
    "associated labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc151b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "for i, (image, label) in enumerate(train_dataset):\n",
    "    if i == 15:\n",
    "        break\n",
    "    image = (image / 2 + .5).numpy()  # reverse transformation\n",
    "    ax = plt.subplot(5, 5, i + 1)\n",
    "    ax.set_title(classes[label])\n",
    "    plt.imshow(image[0])\n",
    "\n",
    "plt.savefig(\"sample_images.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e241d78",
   "metadata": {},
   "source": [
    "#### PopTorch DataLoader\n",
    "We can feed batches of data into a PyTorch model by simply passing the input\n",
    "tensors. However, this is unlikely to be the most efficient way and can\n",
    "result in data loading being a bottleneck to the model, slowing down the\n",
    "training process. In order to make data loading easier and more efficient,\n",
    "there's the [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html)\n",
    "class, which is an `iterable` over a dataset and which can handle parallel data\n",
    "loading, a sampling strategy, shuffling, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ad992",
   "metadata": {},
   "source": [
    "PopTorch offers an extension of this class with its\n",
    "[`poptorch.DataLoader`](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/batching.html#poptorch-dataloader)\n",
    "class, specialised for the way the underlying PopART framework handles\n",
    "batching of data. We will use this class later in the tutorial, as soon as we\n",
    "have a model ready for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec99f4d",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "We will build a simple CNN model for a classification task. To do so, we can\n",
    "simply use PyTorch's API, including `torch.nn.Module`. The difference from\n",
    "what we're used to with pure PyTorch is the _loss computation_, which has to\n",
    "be part of the `forward` function. This is to ensure the loss is computed on\n",
    "the IPU and not on the CPU, and to give us as much flexibility as possible\n",
    "when designing more complex loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b39dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 5, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(5, 12, 5)\n",
    "        self.norm = nn.GroupNorm(3, 12)\n",
    "        self.fc1 = nn.Linear(972, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=0)\n",
    "        self.loss = nn.NLLLoss()\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.norm(self.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.log_softmax(self.fc2(x))\n",
    "        # The model is responsible for the calculation\n",
    "        # of the loss when using an IPU. We do it this way:\n",
    "        if self.training:\n",
    "            return x, self.loss(x, labels)\n",
    "        return x\n",
    "\n",
    "model = ClassificationModel()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee30cc6",
   "metadata": {},
   "source": [
    ">**NOTE**: `self.training` is inherited from `torch.nn.Module` which\n",
    ">initialises its value to `True`. Use `model.eval()` to set it to `False` and\n",
    ">`model.train()` to switch it back to `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce01a7d9",
   "metadata": {},
   "source": [
    "### Prepare training for IPUs\n",
    "The compilation and execution on the IPU can be controlled using\n",
    "`poptorch.Options`. These options are used by PopTorch's wrappers such as\n",
    "`poptorch.DataLoader` and `poptorch.trainingModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3621f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = poptorch.Options()\n",
    "\n",
    "train_dataloader = poptorch.DataLoader(opts,\n",
    "                                       train_dataset,\n",
    "                                       batch_size=16,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66edb994",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "We will need another component in order to train our model: an optimiser.\n",
    "Its role is to apply the computed gradients to the model's weights to optimize\n",
    "(usually, minimize) the loss function using a specific algorithm. PopTorch\n",
    "currently provides classes which inherit from multiple native PyTorch\n",
    "optimisation functions: SGD, Adam, AdamW, LAMB and RMSprop. These optimisers\n",
    "provide several advantages over native PyTorch versions. They embed constant\n",
    "attributes to save performance and memory, and allow you to specify additional\n",
    "parameters such as loss/velocity scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307035bb",
   "metadata": {},
   "source": [
    "We will use [SGD](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/reference.html#poptorch.optim.SGD)\n",
    "as it's a very popular algorithm and is appropriate for this classification\n",
    "task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aac9ff",
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "optimizer = poptorch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa1143c",
   "metadata": {},
   "source": [
    "We now introduce the `poptorch.trainingModel` wrapper, which will handle the\n",
    "training. It takes an instance of a `torch.nn.Module`, such as our custom\n",
    "model, an instance of `poptorch.Options` which we have instantiated\n",
    "previously, and an optimizer. This wrapper will trigger the compilation of\n",
    "our model, using TorchScript, and manage its translation to a program the\n",
    "IPU can run. Let's use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f1fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "poptorch_model = poptorch.trainingModel(model,\n",
    "                                        options=opts,\n",
    "                                        optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6b7ed",
   "metadata": {},
   "source": [
    "#### Training loop\n",
    "Looping through the training data, running the forward and backward passes,\n",
    "and updating the weights constitute the process we refer to as the \"training\n",
    "loop\". Graphcore's Poplar system uses several optimisations to accelerate the\n",
    "training loop. Central to this is the desire to minimise interactions between\n",
    "the device (the IPU) and the host (the CPU), allowing the training loop to\n",
    "run on the device independently from the host. To achieve that virtual\n",
    "independence, Poplar creates a _static_ computational graph and data streams\n",
    "which are loaded to the IPU, and then signals the IPU to get started until\n",
    "there's no data left or until the host sends a signal to stop the loop.\n",
    "\n",
    "![High-level overview of what happens](static/loop.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e795b14",
   "metadata": {},
   "source": [
    "The compilation, which transforms our PyTorch model into a computational\n",
    "graph and our dataloader into data streams, happens at the first call of a\n",
    "`poptorch.trainingModel`. The IPUs to which the graph will be uploaded are\n",
    "selected automatically during this first call, by default. The training loop\n",
    "can then start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c27cf",
   "metadata": {},
   "source": [
    "Once the loop has started, Poplar's main task is to feed the data into the\n",
    "streams and to signal when we are done with the loop. The last step will then\n",
    "be to copy the final graph, meaning the model, back to the CPU - a step that\n",
    "PopTorch manages itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef7e452",
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "for epoch in tqdm(range(epochs), desc=\"epochs\"):\n",
    "    total_loss = 0.0\n",
    "    for data, labels in tqdm(train_dataloader, desc=\"batches\", leave=False):\n",
    "        output, loss = poptorch_model(data, labels)\n",
    "        total_loss += loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2c631d",
   "metadata": {},
   "source": [
    "The model is now trained! There's no need to retrieve the weights from the\n",
    "device as you would by calling `model.cpu()` with PyTorch. PopTorch has\n",
    "managed that step for us. We can now save and evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e3104",
   "metadata": {},
   "source": [
    "#### Use the same IPU for training and inference\n",
    "After the model has been attached to the IPU and compiled after the first call\n",
    "to the PopTorch model, it can be detached from the device. This allows PopTorch\n",
    "to use a single device for training and inference (described below), rather\n",
    "than using 2 IPUs (one for training and one for inference) when the device\n",
    "is not detached. When using an IPU-POD system, detaching from the device will\n",
    "be necessary when using a non-reconfigurable partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "poptorch_model.detachFromDevice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19848d1f",
   "metadata": {},
   "source": [
    "#### Save the trained model\n",
    "We can simply use PyTorch's API to save a model in a file, with the original\n",
    "instance of `ClassificationModel` and not the wrapped model.\n",
    "\n",
    "Do not hesitate to experiment with different models: the model provided in this tutorial is saved in the `static` folder if you need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaef52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10675cef",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "The model can be evaluated on a CPU but it is a good idea to use the IPU - since\n",
    "[IPUs are blazing fast](https://www.graphcore.ai/posts/new-graphcore-ipu-benchmarks).\n",
    "Evaluating your model on a CPU is slow if the test dataset is large and/or the model is complex.\n",
    "\n",
    "Since we have detached our model from its training device, the device is now free again\n",
    "and we can use it for the evaluation stage.\n",
    "\n",
    "The steps taken below to define the model for evaluation essentially allow it to\n",
    "run in inference mode. Therefore, you can follow the same steps to use the model\n",
    "to make predictions once it has been deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cf987",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a45c6",
   "metadata": {},
   "source": [
    "To evaluate the model on the IPU, we will use the `poptorch.inferenceModel`\n",
    "class, which has a similar API to `poptorch.trainingModel` except that it\n",
    "doesn't need an optimizer, allowing evaluation of the model without calculating\n",
    "gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adae660",
   "metadata": {},
   "outputs": [],
   "source": [
    "poptorch_model_inf = poptorch.inferenceModel(model, options=opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1ca28",
   "metadata": {},
   "source": [
    "Then we can instantiate a new PopTorch Dataloader object as before in order to\n",
    "efficiently batch our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184372ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = poptorch.DataLoader(opts,\n",
    "                                      test_dataset,\n",
    "                                      batch_size=32,\n",
    "                                      num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1bd64e",
   "metadata": {},
   "source": [
    "This short loop over the test dataset is effectively all that is needed to\n",
    "run the model and generate some predictions. When running the model in\n",
    "inference, we can stop here and use the predictions as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c1739",
   "metadata": {},
   "source": [
    "For evaluation, we can use `scikit-learn`'s standard classification metrics to\n",
    "understand how well our model is performing. This usually takes a list\n",
    "of labels and a list of predictions as the input, both in the same order.\n",
    "Let's make both lists, and run our model in inference mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90d640",
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "predictions, labels = [], []\n",
    "for data, label in test_dataloader:\n",
    "    predictions += poptorch_model_inf(data).data.max(dim=1).indices\n",
    "    labels += label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5726039",
   "metadata": {},
   "source": [
    "Release IPU resources again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e411614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "poptorch_model_inf.detachFromDevice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a8c4b7",
   "metadata": {},
   "source": [
    "A simple and widely-used performance metric for classification models is the\n",
    "accuracy score, which simply counts how many predictions were right. But this\n",
    "metric alone isn't enough. For example, it doesn't tell us how the model\n",
    "performs with regard to the different classes in our data. We will therefore\n",
    "use another popular metric: a confusion matrix, which tells how much our\n",
    "model confuses a class for another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e982cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, \\\n",
    "    ConfusionMatrixDisplay\n",
    "\n",
    "print(f\"Eval accuracy: {100 * accuracy_score(labels, predictions):.2f}%\")\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "cm_plot = ConfusionMatrixDisplay(cm, display_labels=classes)\\\n",
    "    .plot(xticks_rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f7c00",
   "metadata": {},
   "source": [
    "As you can see, although we've got an accuracy score of ~88%, the model's\n",
    "performance across the different classes isn't equal. Trousers are very well\n",
    "classified, with more than 96-97% accuracy whereas shirts are harder to\n",
    "classify with less than 60% accuracy, and it seems they often get confused\n",
    "with T-shirts, pullovers and coats. So, some work is still required here to\n",
    "improve your model for all the classes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae12726",
   "metadata": {},
   "source": [
    "We can save this visualisation of the confusion matrix. Don't hesitate to experiment: you can then compare your confusion matrix with the [visualisation provided in the `static` folder](static/confusion_matrix.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f83ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot.figure_.savefig(\"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cd0652",
   "metadata": {},
   "source": [
    "# Doing more with `poptorch.Options`\n",
    "This class encapsulates the options that PopTorch and PopART will use\n",
    "alongside our model. Some concepts, such as \"batch per iteration\" are\n",
    "specific to the functioning of the IPU, and within this class some\n",
    "calculations are made to reduce risks of errors and make it easier for\n",
    "PyTorch users to use IPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadebbf7",
   "metadata": {},
   "source": [
    "The list of these options is available in the [documentation](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/overview.html#options).\n",
    "Let's introduce here 4 of these options to get an idea of what they cover."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcfd068",
   "metadata": {},
   "source": [
    "### `deviceIterations`\n",
    "Remember the training loop we have discussed previously. A device iteration\n",
    "is one cycle of that loop, which runs entirely on the IPU (the device), and\n",
    "which starts with a new batch of data. This option specifies the number of\n",
    "batches that is prepared by the host (CPU) for the IPU. The higher this\n",
    "number, the less the IPU has to interact with the CPU, for example to request\n",
    "and wait for data, so that the IPU can loop faster. However, the user will\n",
    "have to wait for the IPU to go over all the iterations before getting the\n",
    "results back. The maximum is the total number of batches in your dataset, and\n",
    "the default value is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23811cef",
   "metadata": {},
   "source": [
    "### `replicationFactor`\n",
    "This is the number of replicas of a model. A replica is a copy of a same\n",
    "model on multiple devices. We use replicas as an implementation of data\n",
    "parallelism, where a same model is served with several batches of data at the\n",
    "same time but on different devices, so that the gradients can be pooled. To\n",
    "achieve the same behaviour in pure PyTorch, you'd wrap your model with\n",
    "`torch.nn.DataParallel`, but with PopTorch, this is an option. Of course, each\n",
    "replica requires one IPU. So, if the `replicationFactor` is two, two IPUs are\n",
    "required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af3547f",
   "metadata": {},
   "source": [
    "### `randomSeed`\n",
    "An advantage of the IPU architecture is an on-device pseudo-random number\n",
    "generator (PRNG). This option sets both the seed for the PRNG on the IPU\n",
    "and PyTorch's seed, which is usually set using `torch.manual_seed`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c7c87",
   "metadata": {},
   "source": [
    "### `useIpuModel`\n",
    "An IPU Model is a simulation, running on a CPU, of an actual IPU. This can be\n",
    "helpful if you're working in an environment where no IPUs are available but\n",
    "still need to make progress on your code. However, the IPU Model doesn't\n",
    "fully support replicated graphs and its numerical results can be slightly\n",
    "different from what you would get with an actual IPU. You can learn more\n",
    "about the IPU Model and its limitations with our\n",
    "[documentation](https://docs.graphcore.ai/projects/poplar-user-guide/en/latest/poplar_programs.html?highlight=ipu%20model#programming-with-poplar)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59aae7a",
   "metadata": {},
   "source": [
    "## How to set the options\n",
    "These options are callable, and chainable as they return the instance. One\n",
    "can therefore do as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ecf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = poptorch.Options()\\\n",
    "    .deviceIterations(20)\\\n",
    "    .replicationFactor(2)\\\n",
    "    .randomSeed(123)\\\n",
    "    .useIpuModel(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ec3fd",
   "metadata": {},
   "source": [
    "# Going further"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57488fd1",
   "metadata": {},
   "source": [
    "Other tutorials will be made available in the future to explore more advanced\n",
    "features and use cases for PopTorch. Make sure you've subscribed to our\n",
    "newsletter to stay up to date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e14112",
   "metadata": {},
   "source": [
    "In the meantime, to learn more about the IPU and the lower level Poplar\n",
    "libraries and graph programming framework, you can go through our Poplar\n",
    "tutorials and read our Poplar SDK overview."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
